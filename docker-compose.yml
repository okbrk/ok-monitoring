services:
  # Grafana - Admin-only access via Tailscale VPN
  grafana:
    image: grafana/grafana:11.0.0
    container_name: grafana
    restart: unless-stopped
    user: "472" # Grafana user ID - fixes permission issues
    ports:
      - "3000:3000" # Exposed on host, but NOT via Caddy
    environment:
      - GF_SERVER_ROOT_URL=http://${TAILSCALE_IP:-localhost}:3000
      - GF_AUTH_ANONYMOUS_ENABLED=false
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_INSTALL_PLUGINS=
    volumes:
      - ${DATA_DIR}/grafana:/var/lib/grafana
      - ./config/grafana/datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml:ro
      - ./config/grafana/dashboards.yaml:/etc/grafana/provisioning/dashboards/dashboards.yaml:ro
    networks:
      - observability
    depends_on:
      - loki
      - mimir
      - tempo

  # Loki - Multi-tenant log aggregation
  loki:
    image: grafana/loki:3.0.0
    container_name: loki
    restart: unless-stopped
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/loki.yaml
    environment:
      - S3_ENDPOINT=${WASABI_ENDPOINT}
      - S3_REGION=${WASABI_REGION}
      - S3_LOKI_BUCKET=${S3_LOKI_BUCKET}
      - S3_LOKI_ACCESS_KEY_ID=${S3_LOKI_ACCESS_KEY_ID}
      - S3_LOKI_SECRET_ACCESS_KEY=${S3_LOKI_SECRET_ACCESS_KEY}
    volumes:
      - ./config/loki/loki.yaml:/etc/loki/loki.yaml:ro
      - ${DATA_DIR}/loki:/loki
    networks:
      - observability

  # Mimir - Multi-tenant metrics storage
  mimir:
    image: grafana/mimir:2.12.0
    container_name: mimir
    restart: unless-stopped
    ports:
      - "8080:8080"
    command:
      - -config.file=/etc/mimir/mimir.yaml
      - -target=all
    environment:
      - S3_ENDPOINT=${WASABI_ENDPOINT}
      - S3_REGION=${WASABI_REGION}
      - S3_MIMIR_BUCKET=${S3_MIMIR_BUCKET}
      - S3_MIMIR_ACCESS_KEY_ID=${S3_MIMIR_ACCESS_KEY_ID}
      - S3_MIMIR_SECRET_ACCESS_KEY=${S3_MIMIR_SECRET_ACCESS_KEY}
    volumes:
      - ./config/mimir/mimir.yaml:/etc/mimir/mimir.yaml:ro
      - ${DATA_DIR}/mimir:/data
    networks:
      - observability

  # Tempo - Multi-tenant distributed tracing
  tempo:
    image: grafana/tempo:2.4.0
    container_name: tempo
    restart: unless-stopped
    ports:
      - "3200:3200" # Tempo HTTP
      - "4317" # OTLP gRPC
      - "4318" # OTLP HTTP
    command:
      - -config.file=/etc/tempo/tempo.yaml
    environment:
      - S3_ENDPOINT=${WASABI_ENDPOINT}
      - S3_REGION=${WASABI_REGION}
      - S3_TEMPO_BUCKET=${S3_TEMPO_BUCKET}
      - S3_TEMPO_ACCESS_KEY_ID=${S3_TEMPO_ACCESS_KEY_ID}
      - S3_TEMPO_SECRET_ACCESS_KEY=${S3_TEMPO_SECRET_ACCESS_KEY}
    volumes:
      - ./config/tempo/tempo.yaml:/etc/tempo/tempo.yaml:ro
      - ${DATA_DIR}/tempo:/var/tempo
    networks:
      - observability

  # OpenTelemetry Collector - Gateway for customer data
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.100.0
    container_name: otel-collector
    restart: unless-stopped
    ports:
      - "4317:4317" # OTLP gRPC
      - "4318:4318" # OTLP HTTP
      - "8888:8888" # Prometheus metrics
    command:
      - --config=/etc/otel-collector/config.yaml
    volumes:
      - ./config/otel-collector/config.yaml:/etc/otel-collector/config.yaml:ro
    networks:
      - observability
    depends_on:
      - loki
      - mimir
      - tempo

  # Caddy - Reverse proxy with automatic HTTPS
  caddy:
    image: caddy:2.7-alpine
    container_name: caddy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
      - "443:443/udp" # HTTP/3
    volumes:
      - ./config/caddy/Caddyfile:/etc/caddy/Caddyfile:ro
      - ${DATA_DIR}/caddy/data:/data
      - ${DATA_DIR}/caddy/config:/config
    networks:
      - observability
    depends_on:
      - grafana
      - loki
      - mimir
      - tempo
      - otel-collector
    environment:
      - DOMAIN=${DOMAIN}

  # PostgreSQL - Tenant management database
  postgres:
    image: postgres:16-alpine
    container_name: postgres
    restart: unless-stopped
    environment:
      - POSTGRES_DB=tenants
      - POSTGRES_USER=tenants
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - ${DATA_DIR}/postgres:/var/lib/postgresql/data
      - ./config/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - observability
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U tenants"]
      interval: 10s
      timeout: 5s
      retries: 5

networks:
  observability:
    driver: bridge
